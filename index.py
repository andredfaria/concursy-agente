from crewai import Agent, Task, Crew
import os
from dotenv import load_dotenv
from llm_config import LLMFactory, LLMProvider

# Carregar variÃ¡veis do arquivo .env
load_dotenv()

def select_llm_provider():
    """
    Permite ao usuÃ¡rio selecionar o provider de LLM a ser usado
    
    Returns:
        tuple: (provider_name, llm_instance)
    """
    factory = LLMFactory()
    available_providers = factory.list_available_providers()
    provider_info = factory.get_provider_info()
    
    print("ðŸ¤– Providers de LLM DisponÃ­veis:")
    print("-" * 50)
    
    available_list = []
    for i, (provider, is_available) in enumerate(available_providers.items(), 1):
        status = "âœ… DisponÃ­vel" if is_available else "âŒ NÃ£o instalado"
        info = provider_info[provider]
        
        print(f"{i}. {info['name']} - {status}")
        print(f"   ðŸ“ {info['description']}")
        
        if is_available:
            available_list.append(provider)
            if info['requires_api_key']:
                env_var = info['env_var']
                api_key_set = "âœ… Configurada" if os.getenv(env_var.split()[0]) else "âŒ NÃ£o configurada"
                print(f"   ðŸ”‘ API Key ({env_var}): {api_key_set}")
        else:
            print(f"   ðŸ“¦ Instalar: {info['install_command']}")
        print()
    
    # Se apenas OpenAI estiver disponÃ­vel, usar automaticamente
    if len(available_list) == 1 and LLMProvider.OPENAI in available_list:
        print(f"ðŸŽ¯ Usando automaticamente: {provider_info[LLMProvider.OPENAI]['name']}")
        return LLMProvider.OPENAI, factory.create_llm(LLMProvider.OPENAI)
    
    # Se nenhum provider estiver disponÃ­vel
    if not available_list:
        raise RuntimeError("âŒ Nenhum provider de LLM estÃ¡ disponÃ­vel! "
                         "Instale pelo menos um dos providers listados acima.")
    
    # Permitir seleÃ§Ã£o manual
    while True:
        try:
            print("ðŸŽ¯ Escolha um provider (nÃºmero):")
            choice = input("> ").strip()
            
            if choice.isdigit():
                choice_idx = int(choice) - 1
                all_providers = list(available_providers.keys())
                
                if 0 <= choice_idx < len(all_providers):
                    selected_provider = all_providers[choice_idx]
                    
                    if selected_provider in available_list:
                        print(f"âœ… Usando: {provider_info[selected_provider]['name']}")
                        return selected_provider, factory.create_llm(selected_provider)
                    else:
                        print("âŒ Este provider nÃ£o estÃ¡ disponÃ­vel. Instale as dependÃªncias primeiro.")
                else:
                    print("âŒ OpÃ§Ã£o invÃ¡lida. Tente novamente.")
            else:
                print("âŒ Digite um nÃºmero vÃ¡lido.")
        except KeyboardInterrupt:
            print("\nðŸ‘‹ OperaÃ§Ã£o cancelada.")
            exit(0)
        except Exception as e:
            print(f"âŒ Erro: {e}")

def get_llm_from_config():
    """
    ObtÃ©m o LLM baseado na configuraÃ§Ã£o do ambiente ou seleÃ§Ã£o interativa
    
    Returns:
        LLM instance
    """
    # Verificar se hÃ¡ uma configuraÃ§Ã£o especÃ­fica no .env
    preferred_provider = os.getenv("PREFERRED_LLM_PROVIDER", "").lower()
    
    if preferred_provider and preferred_provider in LLMFactory.list_available_providers():
        try:
            print(f"ðŸŽ¯ Usando provider configurado: {preferred_provider}")
            return LLMFactory.create_llm(preferred_provider)
        except Exception as e:
            print(f"âš ï¸ Erro ao usar provider configurado ({preferred_provider}): {e}")
            print("ðŸ”„ Caindo para seleÃ§Ã£o interativa...")
    
    # SeleÃ§Ã£o interativa
    _, llm = select_llm_provider()
    return llm

# Configurar o modelo LLM
print("ðŸš€ Configurando modelo de LLM...")
try:
    llm = get_llm_from_config()
    print("âœ… LLM configurado com sucesso!")
except Exception as e:
    print(f"âŒ Erro na configuraÃ§Ã£o do LLM: {e}")
    exit(1)

# ConfiguraÃ§Ãµes da questÃ£o
prova = "CPA-2O"
tema = "Mercado Financeiro"
nivel = "Dificil"
area = "FinanÃ§as"

# Especialista em ConteÃºdo
especialista = Agent(
    role="Especialista em ConteÃºdo Educacional",
    goal=f"Identificar e estruturar os conceitos fundamentais sobre '{tema}' adequados ao nÃ­vel {nivel}",
    backstory=f"""VocÃª Ã© um professor experiente com doutorado na Ã¡rea de '{area}'. 
    Tem mais de 20 anos de experiÃªncia em concurso da area de '{area}' e Ã© especialista em adaptar conteÃºdos 
    complexos para diferentes nÃ­veis de aprendizado.""",
    verbose=True,
    llm=llm
)

# Gerador de QuestÃµes
gerador = Agent(
    role="Criador de QuestÃµes de MÃºltipla Escolha",
    goal=f"Criar uma questÃ£o de mÃºltipla escolha clara, objetiva e pedagogicamente adequada baseada no edital do {prova}",
    backstory="""VocÃª Ã© um especialista em avaliaÃ§Ã£o educacional com formaÃ§Ã£o em Pedagogia. 
    Tem experiÃªncia em criar questÃµes para vestibulares e concursos. 
    Conhece as melhores prÃ¡ticas para formulaÃ§Ã£o de questÃµes de mÃºltipla escolha.""",
    verbose=True,
    llm=llm
)

# Revisor PedagÃ³gico
revisor = Agent(
    role="Revisor PedagÃ³gico",
    goal=f"Garantir a qualidade, clareza e adequaÃ§Ã£o pedagÃ³gica da questÃ£o finalizada baseada no edital do {prova}",
    backstory="""VocÃª Ã© um pedagogo com especializaÃ§Ã£o em avaliaÃ§Ã£o educacional. 
    Tem experiÃªncia em revisar materiais editais de concursos. 
    Seu trabalho Ã© garantir que a questÃ£o esteja perfeita antes da aplicaÃ§Ã£o.""",
    verbose=True,
    llm=llm
)

# Tarefas Estruturadas
tarefa_especialista = Task(
    description=f"""
    Analise o tema '{tema}' e identifique os 5 pontos principais que devem ser abordados 
    em uma questÃ£o de nÃ­vel {nivel}. 
    
    ForneÃ§a:
    1. Lista dos conceitos fundamentais
    2. Aspectos mais importantes para avaliaÃ§Ã£o
    3. PossÃ­veis conexÃµes com outros temas
    4. SugestÃµes de enfoque adequado ao nÃ­vel
    
    Seja especÃ­fico e educacionalmente relevante.
    """,
    agent=especialista,
    expected_output="Lista estruturada com os pontos principais e orientaÃ§Ãµes pedagÃ³gicas"
)

tarefa_gerador = Task(
    description="""
    Com base na anÃ¡lise do especialista, crie uma questÃ£o de mÃºltipla escolha seguindo este formato:
    
    QUESTÃƒO: [Enunciado claro e objetivo]
    
    A) [Alternativa 1]
    B) [Alternativa 2] 
    C) [Alternativa 3]
    D) [Alternativa 4]
    
    RESPOSTA CORRETA: [Letra e justificativa]
    
    Requisitos:
    - QuestÃ£o clara e sem ambiguidades
    - 4 alternativas plausÃ­veis
    - Apenas uma resposta correta
    - Distratores bem elaborados
    - Linguagem adequada ao nÃ­vel
    """,
    agent=gerador,
    expected_output="QuestÃ£o de mÃºltipla escolha completa com 4 alternativas e resposta correta identificada"
)

# Equipe de CriaÃ§Ã£o de QuestÃµes
equipe = Crew(
    agents=[especialista, gerador],
    tasks=[tarefa_especialista, tarefa_gerador],
    verbose=True,
    process="sequential"  # Processamento sequencial para dependÃªncias
)

# ExecuÃ§Ã£o
if __name__ == "__main__":
    print("\n" + "="*60)
    print("ðŸŽ¯ Iniciando geraÃ§Ã£o de questÃ£o...")
    print(f"ðŸ“š Tema: {tema}")
    print(f"ðŸ“š Prova: {prova}")
    print(f"ðŸ“š Area: {area}")
    print(f"ðŸ“Š NÃ­vel: {nivel}")
    print("-" * 50)
    
    try:
        resultado = equipe.kickoff()
        print("\n" + "="*60)
        print("âœ… QUESTÃƒO FINALIZADA")
        print("="*60)
        print(resultado)
    except Exception as e:
        print(f"âŒ Erro durante a execuÃ§Ã£o: {e}")
        print("ðŸ’¡ Dicas para resolver:")
        print("- Verifique se a API key estÃ¡ correta")
        print("- Verifique se hÃ¡ crÃ©ditos disponÃ­veis na sua conta")
        print("- Tente usar um provider diferente")
